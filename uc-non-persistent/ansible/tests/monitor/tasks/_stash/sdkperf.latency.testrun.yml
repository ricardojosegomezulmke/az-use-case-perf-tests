# ---------------------------------------------------------------------------------------------
# MIT License
# Copyright (c) 2020, Solace Corporation, Ricardo Gomez-Ulmke (ricardo.gomez-ulmke@solace.com)
# ---------------------------------------------------------------------------------------------

---

- set_fact:
    sample_num: "{{item}}"
    is_warm_up_run: "{{warm_up_run | default(False)}}"
    sdkperf_params:
        msg_payload_size_bytes: "{{monitor.latency.msg_payload_size_bytes}}"
        msg_rate_per_second: "{{monitor.latency.msg_rate_per_second}}"
        lb: "{{monitor.latency.lb}}"
        lg: "{{monitor.latency.lg}}"
        lpm: "{{monitor.latency.lpm}}"

- name: "Determine Sampling Start Time"
  block:
    - name: "get time from local host"
      shell: "date -u +%s"
      register: t_result
      delegate_to: localhost
    - set_fact:
        sample_start_ts_epoch_secs: "{{t_result.stdout}}"
  when: is_warm_up_run == False

- name: "Set Initial Sampling Start Time"
  set_fact:
    sample_start_ts_epoch_secs: "{{run_start_ts_epoch_secs}}"
  when: is_warm_up_run == True

- set_fact:
    sample_end_ts_epoch_secs: "{{(sample_start_ts_epoch_secs | int) + (sample_run_time_secs | int)}}"
    sample_start_ts_str: "{{ '%Y-%m-%d %H:%M:%S%z' | strftime(sample_start_ts_epoch_secs) }}"
    sample_file_name_ts_str: "{{ '%Y-%m-%d-%H-%M-%S%z' | strftime(sample_start_ts_epoch_secs) }}"

# # TEST & DEBUG
# - name: "FORCE FAIL on sample_num==1"
#   fail:
#     msg: "forcing an error: sample_num={{sample_num}}"
#   when: sample_num == "1"

# TEST & DEBUG
# - debug:
#     msg:
#       - "sample_start_ts_epoch_secs={{sample_start_ts_epoch_secs}}"
#       - "sample_start_ts_str={{sample_start_ts_str}}"
#       - "sample_end_ts_epoch_secs={{sample_end_ts_epoch_secs}}"
#       - "sdkperf_msg_number={{sdkperf_msg_number}}"
# - pause:
#     seconds: 5

- name: "Run 'sdkperf' ..."
  shell: >
    taskset -c 1,2
    {{sdkperf_nodes.sdkperf_root}}/sdkperf-c-x64/sdkperf_c.sh
    -cip={{broker_uri}}:{{sdkperf.broker_port}}
    -cn={{hostvars[inventory_hostname].boxname}}-1
    -cu={{ sdkperf.client_publisher_username }}@{{ sdkperf.broker_msg_vpn }}
    -cp={{ sdkperf.client_publisher_password }}
    -ptl={{ monitor.latency.topic_prefix }}/{{stats_name}}
    -stl={{ monitor.latency.topic_prefix }}/{{stats_name}}
    -mn={{ sdkperf_msg_number }}
    -msa={{ monitor.latency.msg_payload_size_bytes }}
    -mr={{ monitor.latency.msg_rate_per_second }}
    -psm
    {{'-lpm' if monitor.latency.lpm else '' }}
    -l
    -lwu={{monitor.latency.warmup_secs}}
    -lb={{monitor.latency.lb}}
    -lg={{monitor.latency.lg}}
  async: "{{sample_run_time_secs}}"
  poll: 5
  register: sdkperf_result
  failed_when: "'Exception' in sdkperf_result.stderr or sdkperf_result.stdout == ''"

- name: "Parse sdkperf output as json"
  set_fact:
    # fails if output is not JSON
    sdkperf_output_json: "{{sdkperf_result.stdout | from_json}}"

- name: "Post-process latency results"
  template:
    src: "{{ latency_pp_j2_template_file }}"
    dest: "{{ result_dir }}/{{stats_name}}.{{sample_file_name_ts_str}}.j2.json"
  delegate_to: localhost
  when: monitor.latency.lpm

- meta: end_play

- name: "Post-process latency results"
  command: "{{latency_post_process_exe}}"
  environment:
    RUN_ID: "{{run_id}}"
    SAMPLE_NUM: "{{sample_num}}"
    TEMPLATE_FILE: "{{latency_post_process_template_file}}"
    START_TIMESTAMP_STR: "{{sample_start_ts_str}}"
    LATENCY_OUTPUT: "{{sdkperf_result.stdout}}"
    SDKPERF_COMMAND: "{{sdkperf_result.cmd}}"
    SDKPERF_PARAMS_JSON: "{{sdkperf_params|to_json}}"
    STATS_NAME: "{{stats_name}}"
    INVENTORY_HOST: "{{inventory_hostname}}"
  delegate_to: localhost
  register: pp_result
  failed_when: pp_result.rc > 0 or pp_result.stderr != ''

- set_fact:
    pp_latency_json: "{{pp_result.stdout | from_json}}"


# see what TK produces
# if native output is a json already, use jinja2 to create the final version
# if not, leave it
- name: "Add index numbers to lpm array"
  template:
    src: "{{ latency_pp_j2_template_file }}"
    dest: "{{ result_dir }}/{{stats_name}}.{{sample_file_name_ts_str}}.j2.json"
  delegate_to: localhost
  when: monitor.latency.lpm

- name: "Copy Latency Json to {{stats_name}}.{{sample_file_name_ts_str}}.json"
  copy:
    content: "{{pp_latency_json | to_nice_json }}"
    dest: "{{ result_dir }}/{{stats_name}}.{{sample_file_name_ts_str}}.json"
  delegate_to: localhost
  when: is_warm_up_run == False

- name: "Wait for sample cyle to complete"
  block:
    - name: "get time from local host"
      shell: "date -u +%s"
      register: t_result
      delegate_to: localhost
    - set_fact:
        # -1: ensures that there is at least 1 sample in every minute
        wait_secs: "{{(sample_end_ts_epoch_secs | int) - (t_result.stdout | int) - 1 }}"
    - name: "Check playbook execution time is within time span"
      fail:
        msg: "sampling execution time is too long, waiting for {{wait_secs}} is not possible. fix playbook."
      when: is_warm_up_run == False and wait_secs|int < 0
    - name: "Wait for sample cycle to complete"
      pause:
        seconds: "{{wait_secs}}"
  when: sample_num|int < (monitor.general.total_num_samples-1)


###
# The End.
