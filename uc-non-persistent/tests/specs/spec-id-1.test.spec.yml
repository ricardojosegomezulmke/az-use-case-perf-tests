# ---------------------------------------------------------------------------------------------
# MIT License
# Copyright (c) 2020, Solace Corporation, Ricardo Gomez-Ulmke (ricardo.gomez-ulmke@solace.com)
# ---------------------------------------------------------------------------------------------

# cloud_provider + infrastructure_id - required
# add fanout ratio?
#  - yes
#  - dynamic publiser assignment to vms
#  - calculate number of consumers per consumer vm that was provisioned
# run tests in parallel on all infrastructures?
# - should organize runs by infrastructure id?

    # matrix concept:
    #   - infrastructure-id:
    #     - {cloud-provider}.{config-id}
    #   - for infrastructures
    #     - cloud-provider: azure, aws
    #     - config-id: infra1-standalone, infra2-standalone

    #   strategy:
    #     fail-fast: true
    #     matrix:
    #       cloud_provider_id: [azure, aws]
    #       config_id: [infra1-standalone, infra2-standalone]

---
  test_spec:
    use_case: uc_non_persistent
    total_num_samples_per_run: 60
    sample_duration_secs_per_run: 10
    run_defaults:
      infrastructure:
        cloud_provider: azure
        id: rjgu-standalone
      load:
        include: true
        num_pubs: 4
        pub_num_topics: 100 # auto generate them and generate the consumers based on fan-out ratio
        pub_msg_rate_per_second: 100000 #

        # 50 - 60K outbound messages per second
        # e.g.
        #   - 1 producer, 40 consumers receiving 1/40 of the messages
        #     fan-out of 1
        #
        pub_msg_payload_size_bytes: 100 # 100 || 500 || 1000
        # calculate the total number of messages published
        # don't write log files
        # calculate the sub topics based on fan-out: 1 to 4

        # ratio-instances: 2,
        # ratio-fanout: 4 ==> each sub must subscribe to 2 topics
        pubs_to_subs_ratio: 4
      monitors:
        latency:
          include: true
          topic_prefix: "private/direct/latency"
          warmup_secs: 10
          msg_rate_per_second: 1000 # 0=max
          msg_payload_size_bytes: 100 # 100 || 1000 || 10000 || etc...
          lg: 15
          lb: 4096
          lpm: true
        latency_brokernode:
          include: true
          topic_prefix: "private/direct/latency-brokernode"
          warmup_secs: 10
          msg_rate_per_second: 1000 # 0=max
          msg_payload_size_bytes: 100 # 100 || 1000 || 10000 || etc...
          lg: 15
          lb: 4096
          lpm: true
        ping:
          include: true
        vpn:
          include: true
    runs:
      # add all this to meta for the run
      # include number of samples if not there
      - name: run_az_base
      - name: run_az_var_1
        monitors:
          latency:
            lpm: false
          latency_brokernode:
            lpm: false
      - name: run_aws_base
        infrastructure:
          cloud_provider: aws
          id: rjgu-standalone
      - name: run_aws_var_1
        infrastructure:
          cloud_provider: aws
          id: rjgu-standalone
        monitors:
          latency:
            lpm: false
          latency_brokernode:
            lpm: false


###
# The End.
